## PROJECT WebPage-Classifier-Engine

[Introduction](#introduction)
1. [Port Scanning](#port-scanning)
2. [Web Page donwloading](#web-page-downloading)
    - [Html](#html)
    - [Headers](#headers)
    - [image](#image)


### Introduction
The main aim of WebPage-Classifier-Engine is to be able to access, identify, and evaluate the.onion or clearnet web pages based on the keywords provided by the user. In addition, web pages are also evaluated based on their HTML properties such as the `HTML to text ratio`, the existence of certain `HTML headers` in the HTTP response of the website. The program applies request-library to fetch webpages and Pysocks library to interact with the Tor Linux library. For the classification of webpages, Spacy (Natural Language Processing) was employed.

### Installation
Download the tor library from your respective linux repository

```bash
sudo apt-get install tor
```

It would be wise to first set up a virtual environment and then install the requirements.txt. Once the `Spacy=2.2.4` has been installed, the spacy English language models must be installed `en_core_web_lg` & `en_core_web_sm`. (The essential language models are downloaded only after the requirements.txt has been installed, since the `Spacy=2.2.4` is required to run the project.)

```bash
python -m spacy en_core_web_lg
```

```bash
python -m spacy en_core_web_sm
```

### Usage
The program can be run using the bash script `run.sh`.

```bash
bash run.sh
```

The script will run [WebPageDownloader.py](WebPageDownloader.py), which will prompt for a file path containing a list of URLs. The package contains a folder called [`Key_List`](Key_List) containing five text files. Files are used to specify keywords, if found in the html content, will be used to calculate the ranking of the pages.

**Example :** [emails_list](Key_List/emails_list) has the keyword 'imam@gmail.com'. The program [webpageclassifier.py](webpageclassifier.py) when classifying the webpage will look
for this particular email-id. Considering the find, the program will assign some more weight to the webpage the emailId was found in, in comparisson to the others it didn't find it in. Same goes with the other lists. 

The full working can be understood below.

### Port Scanning
Port scanning is performed via Pysocks library and only over selected ports, which is why port numbers are hard-coded port in the program itself. This is because tor has a protective mechanism in place that detects port scanning whenever an unrecognized port is accessed, thus considering the above-mentioned condition a time delay of one second was introduced while coding the part of the scanner and no threading was employed. This is based on the [(2019)research paper's](https://dl.acm.org/doi/pdf/10.1145/3339252.3341486?download=true) finding. The port numbers list will have to set manually by editing the code [portScanner.py](portScanner.py).

### Web Page donwloading
This being the parent script of all the scripts is called first when executing the `run.sh`. The websites are downloaded in the hierarchy as follows.

```
{DATE}_hour
    |
    |---HTML
        |
        |--{urlname}.html..
    |---Headers
        |
        |--{urlname}_headers.json..
    |---Images
        |
        |--{urlname}.png..
    |---downloaded.json
    |---final_1.json
    |---report.html
```

The `downloaded.json` (intial json downloads indexing which webpages were downloaded, redundancy file incase the classifier is needed to be rerun) is generated by [WebPageDownloader.py](WebPageDownloader.py), `final_1.json`( is the final json file, used to generate report) by the [webpageclassifier.py](webpageclassifier.py) and `report.html` by [webPageAnalyzer.py](webPageAnalyzer.py).

The keys of the `downloaded.json` are subset of `final_1.json`. The keys(self-explanatory) of `final_1.json` are:

```json
[{"url": "", "port": "", "is_redirect": True , "html_response": , "html_path": "2020-06-26_00/HTML/https:__{url}l", "headers_path": "2020-06-26_00/Headers/https:__{url}_header.json", "image_path": "2020-06-26_00/Images/https:__{url}.png", "script": false, "interest": 1.27, "location_list": [], "person_list": [], "dates_list": [], "organisation_list": [], "emails_list": [], "combo_basic": []}]
```
